name: Pipeline Test Generator

on:
  push:
    branches:
      - pipeline

jobs:
  generate_and_test:
    runs-on: ubuntu-latest

    permissions:
      contents: write
      pull-requests: write

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0 

      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install boto3
          pip install requests  # For Pushgateway

      # ========================================
      # WORKFLOW START - Push to Prometheus
      # ========================================
      - name: Push workflow start metrics
        env:
          PUSHGATEWAY_URL: ${{ secrets.PUSHGATEWAY_URL }}
        run: python push_metrics.py start

      # ========================================
      # GENERATE TESTS
      # ========================================
      - name: Generate tests
        id: generate
        env:
          API_KEY: ${{ secrets.API_KEY }}
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_REGION }}
        run: python generate_tests.py

      # ========================================
      # VERIFY METRICS FILE WAS CREATED
      # ========================================
      - name: Verify metrics file
        run: |
          echo "üìä Checking if metrics_summary.json was created..."
          if [ -f "metrics_summary.json" ]; then
            echo "‚úÖ metrics_summary.json found"
            cat metrics_summary.json
          else
            echo "‚ùå metrics_summary.json NOT found!"
            exit 1
          fi

      # ========================================
      # VALIDATE TESTS
      # ========================================
      - name: Validate LLM Generated Tests
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_REGION }}
        run: python validate_generated_test.py

      # ========================================
      # RUN TESTS
      # ========================================
      - name: Run tests
        id: run_tests
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_REGION }}
        run: python run_tests.py
        continue-on-error: true

      # ========================================
      # PUSH METRICS TO PROMETHEUS
      # ========================================
      - name: Push workflow metrics
        if: always()
        env:
          PUSHGATEWAY_URL: ${{ secrets.PUSHGATEWAY_URL }}
        run: |
          echo "üì§ Pushing metrics to Pushgateway..."
          
          # Verify files exist
          echo "Checking for required files:"
          ls -la metrics_summary.json test_stdout.txt 2>/dev/null || echo "Some files missing"
          
          # Push metrics
          python push_metrics.py custom
          
          echo "‚úÖ Metrics push completed"

      # ========================================
      # MARK WORKFLOW END
      # ========================================
      - name: Push workflow completion
        if: always()
        env:
          PUSHGATEWAY_URL: ${{ secrets.PUSHGATEWAY_URL }}
        run: |
          if [ "${{ steps.run_tests.outcome }}" == "success" ]; then
            python push_metrics.py end success
          else
            python push_metrics.py end failure
          fi

      # ========================================
      # UPLOAD ARTIFACTS FOR DEBUGGING
      # ========================================
      - name: Upload metrics and test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: workflow-outputs
          path: |
            generated_test.py
            metrics_summary.json
            test_stdout.txt
            test_stderr.txt
      
      - name: Get commit message
        id: msg
        run: echo "message=$(git log -1 --pretty=%B)" >> $GITHUB_OUTPUT

      # ========================================
      # CLEANUP: Remove temporary files
      # ========================================
      - name: Clean up temporary files
        run: |
          echo "üßπ Cleaning up temporary files..."
          
          # Remove test execution artifacts
          rm -f test_stdout.txt
          rm -f test_stderr.txt
          rm -f metrics_summary.json
          rm -f failed_tests.py
          rm -f prompt_used.txt
          rm -f diff.patch
          
          # List what remains
          echo "Files after cleanup:"
          git status --short
          
          echo "‚úÖ Cleanup complete"

      # ========================================
      # RESET WORKFLOW FILE
      # ========================================
      - name: Reset workflow file
        run: |
          # This prevents the workflow file changes from being included in the PR
          git checkout origin/main -- .github/workflows/test_pipeline.yml
          echo "‚úÖ Workflow file reset to main branch version"

      # ========================================
      # DEBUG: Show what will be committed
      # ========================================
      - name: Debug - Show PR contents
        run: |
          echo "================================"
          echo "üîç Files that will be in PR:"
          echo "================================"
          
          # Show git status
          git status --short
          
          # Show files different from main
          echo ""
          echo "Files different from main branch:"
          git diff --name-only origin/main...HEAD | while read file; do
            if [ -f "$file" ]; then
              echo "  ‚úÖ $file"
            fi
          done
          
          # Check specific files
          echo ""
          echo "Specific checks:"
          [ -f "generated_test.py" ] && echo "  ‚úÖ generated_test.py exists" || echo "  ‚ùå generated_test.py missing"
          [ -f "app.py" ] && echo "  ‚úÖ app.py exists" || echo "  ‚ùå app.py missing"
          [ -f "test_stdout.txt" ] && echo "  ‚ö†Ô∏è  test_stdout.txt still exists (should be removed)" || echo "  ‚úÖ test_stdout.txt removed"
          [ -f "metrics_summary.json" ] && echo "  ‚ö†Ô∏è  metrics_summary.json still exists (should be removed)" || echo "  ‚úÖ metrics_summary.json removed"
          
          echo "================================"

      # ========================================
      # CREATE PR
      # ========================================
      - name: Create Pull Request
        uses: peter-evans/create-pull-request@v5
        with:
          commit-message: "Update generated tests"
          title: "Auto: Updated tests"
          body: "Generated tests for: ${{ steps.msg.outputs.message }}"
          branch: pipeline   # important: PR comes from pipeline!
          base: main
          

            
         